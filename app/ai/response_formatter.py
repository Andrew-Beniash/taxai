"""
Response Formatter for Tax Law Application

This module enhances AI-generated responses with properly structured and formatted
citations to tax law references, ensuring clear attribution and easy verification.
"""

import re
import logging
from typing import Dict, List, Any, Optional

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def format_response(ai_answer: str, references: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Formats AI-generated responses with properly structured citations.
    
    Args:
        ai_answer: The raw answer generated by the AI model
        references: List of reference documents used to generate the answer
    
    Returns:
        A structured response with the answer and formatted citations
    """
    # Format the inline citations in the AI answer
    formatted_answer = format_inline_citations(ai_answer, references)
    
    # Format references into a clear, easy-to-reference structure
    formatted_citations = []
    for i, ref in enumerate(references, 1):
        # Extract metadata from the reference
        source = ref.get("metadata", {}).get("source", "Unknown Source")
        content = ref.get("content", "")
        
        # Create a snippet of the content (limited length)
        content_snippet = content[:200] + "..." if len(content) > 200 else content
        
        # Build the citation object
        citation = {
            "source": source,
            "text": content_snippet,
        }
        
        # Add URL if available
        url = ref.get("metadata", {}).get("url")
        if url:
            citation["url"] = url
            
        formatted_citations.append(citation)
    
    # Calculate confidence score based on reference quality
    confidence_score = calculate_confidence_score(formatted_answer, references)
    
    # Return the structured response
    return {
        "response": formatted_answer,
        "citations": formatted_citations,
        "confidence_score": confidence_score,
        "is_mock": False
    }

def format_inline_citations(ai_answer: str, references: List[Dict[str, Any]]) -> str:
    """
    Enhances the AI answer by ensuring it has proper inline citation numbers
    that correspond to the references list.
    
    Args:
        ai_answer: The raw answer generated by the AI model
        references: List of reference documents
    
    Returns:
        AI answer with properly formatted inline citations
    """
    formatted_answer = ai_answer
    
    # Check if there are any citation patterns like [X] already in the answer
    citation_pattern = r'\[(\d+)\]'
    existing_citations = re.findall(citation_pattern, formatted_answer)
    
    # If no citations are found, try to add them based on key phrases
    if not existing_citations and references:
        # For each reference, check if its content appears in the answer
        for i, ref in enumerate(references, 1):
            content = ref.get("content", "").lower()
            source = ref.get("metadata", {}).get("source", "").lower()
            
            # Extract key phrases (first 5-10 words of content)
            key_words = content.split()[:10]
            key_phrase = " ".join(key_words)
            
            # If content is short, use the whole thing as a key phrase
            if len(key_words) < 5:
                key_phrase = content
                
            # Check if the source name appears in the answer
            if source and len(source) > 5 and source in formatted_answer.lower():
                # Add citation after the source name if it's not already cited
                citation_id = f"[{i}]"
                
                # Use regex to find the source name with word boundaries
                source_pattern = re.compile(re.escape(source), re.IGNORECASE)
                matches = source_pattern.finditer(formatted_answer.lower())
                
                # Get all match positions
                positions = [match.start() for match in matches]
                
                # Add citations if positions found and not already cited
                if positions and citation_id not in formatted_answer:
                    # Insert after the first occurrence
                    pos = positions[0] + len(source)
                    formatted_answer = formatted_answer[:pos] + f" {citation_id}" + formatted_answer[pos:]
    
    return formatted_answer

def calculate_confidence_score(response: str, references: List[Dict[str, Any]]) -> float:
    """
    Calculates a confidence score based on the quality and quantity of references.
    
    Args:
        response: The formatted AI response
        references: List of reference documents used
    
    Returns:
        A confidence score between 0 and 1
    """
    # Base confidence starts at 0.5
    base_score = 0.5
    
    # No references results in lower confidence
    if not references:
        return 0.4
    
    # More references generally indicate higher confidence (up to 3 references)
    reference_score = min(0.2, len(references) * 0.05)
    
    # Check if response includes citations
    citation_pattern = r'\[(\d+)\]'
    citation_count = len(re.findall(citation_pattern, response))
    citation_score = min(0.2, citation_count * 0.05)
    
    # Higher confidence for official sources
    official_sources = ['irs', 'treasury', 'tax code', 'internal revenue', 'publication']
    has_official_source = any(
        any(source.lower() in ref.get("metadata", {}).get("source", "").lower() for source in official_sources)
        for ref in references
    )
    official_source_score = 0.1 if has_official_source else 0
    
    # Calculate final score
    final_score = base_score + reference_score + citation_score + official_source_score
    
    # Cap at 0.99 - never claim 100% confidence
    return min(0.99, final_score)
